<<<<<<< HEAD
# -*- coding: utf-8 -*-
import streamlit as st
import speech_recognition as sr
from io import BytesIO
from pydub import AudioSegment
import json
import base64

st.set_page_config(page_title="Tr∆∞ng V∆∞∆°ng Garden - Voice Assistant", layout="centered")

st.markdown("<h2 style='text-align:center;'>CH√ÄO M·ª™NG B·∫†N ƒê·∫æN TR∆ØNG V∆Ø∆†NG GARDEN</h2>", unsafe_allow_html=True)
st.markdown("<h4 style='text-align:center;'>TR·ª¢ L√ù A.I B·∫∞NG GI·ªåNG N√ìI TVG</h4>", unsafe_allow_html=True)

st.markdown("""
**H∆∞·ªõng d·∫´n ng·∫Øn:**
1) Nh·∫•n **Ph√°t l·ªùi ch√†o** ƒë·ªÉ nghe gi·ªõi thi·ªáu.
2) Nh·∫•n **B·∫•m ƒë·ªÉ h·ªèi**, ghi √¢m c√¢u h·ªèi (upload file audio).
3) Tr·ª£ l√Ω tr·∫£ l·ªùi b·∫±ng √¢m thanh.
4) Nh·∫•n **K·∫øt th√∫c** ƒë·ªÉ ch√†o t·∫°m bi·ªát.
""")

# ---- Load FAQ JSON ----
def find_answer(user_text):
    try:
        with open("faq_garden.json", encoding="utf-8") as f:
            faq_data = json.load(f)
    except Exception:
        return "Xin l·ªói, hi·ªán t·∫°i t√¥i kh√¥ng th·ªÉ truy c·∫≠p d·ªØ li·ªáu t∆∞ v·∫•n."

    for item in faq_data.get("faq", []):
        for keyword in item.get("question", []):
            if keyword.lower() in user_text.lower():
                return item.get("answer", "")
    return ("Xin l·ªói, t√¥i ch∆∞a hi·ªÉu c√¢u h·ªèi c·ªßa b·∫°n. "
            "B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ gi·ªù m·ªü c·ª≠a, gi√° v√©, tr·∫£i nghi·ªám, ·∫©m th·ª±c, khuy·∫øn m√£i ho·∫∑c li√™n h·ªá.")

# ---- Ph√°t l·ªùi ch√†o b·∫±ng HTML5 audio (mi·ªÖn ph√≠, tr√¨nh duy·ªát) ----
def play_audio_file(file_path):
    audio_file = open(file_path, "rb").read()
    b64_audio = base64.b64encode(audio_file).decode()
    audio_html = f"""
        <audio autoplay="true" controls>
        <source src="data:audio/mp3;base64,{b64_audio}" type="audio/mp3">
        Your browser does not support the audio element.
        </audio>
    """
    st.markdown(audio_html, unsafe_allow_html=True)

# ---- STT t·ª´ file audio ----
def transcribe_audio(uploaded_file):
    if uploaded_file is None:
        return None
    # Chuy·ªÉn audio v·ªÅ WAV n·∫øu c·∫ßn
    file_bytes = uploaded_file.read()
    audio = AudioSegment.from_file(BytesIO(file_bytes))
    wav_io = BytesIO()
    audio.export(wav_io, format="wav")
    wav_io.seek(0)
    
    recognizer = sr.Recognizer()
    with sr.AudioFile(wav_io) as source:
        audio_data = recognizer.record(source)
        try:
            text = recognizer.recognize_google(audio_data, language='vi-VN')
            return text
        except sr.UnknownValueError:
            return "T√¥i kh√¥ng nghe r√µ, b·∫°n vui l√≤ng n√≥i l·∫°i nh√©!"
        except sr.RequestError:
            return "Hi·ªán t·∫°i kh√¥ng th·ªÉ k·∫øt n·ªëi d·ªãch v·ª• STT."

# ---- MAIN UI ----
col1, col2, col3 = st.columns([1,1,1])

# State
if 'stop' not in st.session_state:
    st.session_state.stop = False

with col1:
    if st.button("‚ñ∂Ô∏è Ph√°t l·ªùi ch√†o"):
        # intro.mp3 ph·∫£i c√≥ trong repo
        play_audio_file("intro.mp3")

with col2:
    uploaded_audio = st.file_uploader("üé§ B·∫•m ƒë·ªÉ h·ªèi", type=["wav", "mp3", "m4a", "webm"])
    if uploaded_audio is not None:
        user_text = transcribe_audio(uploaded_audio)
        st.info(f"B·∫°n n√≥i: {user_text}")
        answer_text = find_answer(user_text)
        st.success(f"Tr·ª£ l√Ω tr·∫£ l·ªùi: {answer_text}")
        # Ph√°t b·∫±ng TTS tr√¨nh duy·ªát
        tts_file = "temp_answer.mp3"
        from gtts import gTTS
        tts = gTTS(text=answer_text, lang="vi")
        tts.save(tts_file)
        play_audio_file(tts_file)

with col3:
    if st.button("‚èπ K·∫øt th√∫c"):
        farewell_text = "C·∫£m ∆°n b·∫°n ƒë√£ s·ª≠ d·ª•ng Tr·ª£ l√Ω Tr∆∞ng V∆∞∆°ng Garden. Ch√†o t·∫°m bi·ªát!"
        st.success(farewell_text)
        tts = gTTS(text=farewell_text, lang="vi")
        tts.save("farewell.mp3")
        play_audio_file("farewell.mp3")
        st.session_state.stop = True

st.markdown("<p style='text-align:center; color: gray;'>S·∫£n ph·∫©m do nh√≥m h·ªçc sinh CLB L·∫≠p tr√¨nh l·ªõp 7C</p>", unsafe_allow_html=True)
=======
# -*- coding: utf-8 -*-
import streamlit as st
import speech_recognition as sr
from io import BytesIO
from pydub import AudioSegment
import json, base64, os
from gtts import gTTS

st.set_page_config(page_title="Tr∆∞ng V∆∞∆°ng Garden - Voice Assistant", layout="centered")

st.markdown("<h2 style='text-align:center;'>CH√ÄO M·ª™NG B·∫†N ƒê·∫æN TR∆ØNG V∆Ø∆†NG GARDEN</h2>", unsafe_allow_html=True)
st.markdown("<h4 style='text-align:center;'>TR·ª¢ L√ù A.I GI·ªåNG N√ìI</h4>", unsafe_allow_html=True)

st.write("""
**H∆∞·ªõng d·∫´n:**
1) Nh·∫•n **Ph√°t l·ªùi ch√†o**
2) Nh·∫•n **üé§ B·∫•m ƒë·ªÉ ghi √¢m**
3) Tr·ª£ l√Ω t·ª± tr·∫£ l·ªùi b·∫±ng √¢m thanh
4) Nh·∫•n **K·∫øt th√∫c**
""")

# ====== LOAD FAQ ======
def find_answer(user_text):
    try:
        with open("faq_garden.json", encoding="utf-8") as f:
            faq_data = json.load(f)
    except:
        return "Xin l·ªói, t√¥i kh√¥ng th·ªÉ truy c·∫≠p d·ªØ li·ªáu t∆∞ v·∫•n."

    for item in faq_data.get("faq", []):
        for kw in item.get("question", []):
            if kw.lower() in user_text.lower():
                return item.get("answer", "")
    return "Xin l·ªói, t√¥i ch∆∞a hi·ªÉu c√¢u h·ªèi c·ªßa b·∫°n."

# ====== PH√ÅT √ÇM THANH ======
def play_audio_file(path):
    audio_bytes = open(path, "rb").read()
    b64 = base64.b64encode(audio_bytes).decode()
    st.markdown(
        f"""
        <audio autoplay controls>
            <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
        </audio>
        """,
        unsafe_allow_html=True,
    )

# ====== STT ======
def transcribe(data):
    audio = AudioSegment.from_file(BytesIO(data))
    wav_io = BytesIO()
    audio.export(wav_io, format="wav")
    wav_io.seek(0)

    rec = sr.Recognizer()
    with sr.AudioFile(wav_io) as src:
        audio_data = rec.record(src)
        try:
            return rec.recognize_google(audio_data, language="vi-VN")
        except:
            return "T√¥i kh√¥ng nghe r√µ, b·∫°n n√≥i l·∫°i nh√©."

# ====== GIAO DI·ªÜN 3 C·ªòT ======
col1, col2, col3 = st.columns([1,2,1])

# ====== BUTTON 1 ======
with col1:
    if st.button("‚ñ∂Ô∏è Ph√°t l·ªùi ch√†o"):
        play_audio_file("intro.mp3")

# ====== BUTTON 2 ‚Äî GHI √ÇM MICRO ======
with col2:
    st.markdown("### üé§ B·∫•m ƒë·ªÉ ghi √¢m c√¢u h·ªèi")

    audio_data = st.experimental_get_query_params().get("audio", [None])[0]

    # N√∫t ghi √¢m b·∫±ng Javascript
    st.markdown("""
    <button id="recBtn" style="padding:10px 20px; font-size:18px;">üé§ B·∫•m ƒë·ªÉ h·ªèi</button>

    <script>
    let recBtn = document.getElementById('recBtn');
    let chunks = [];
    let recorder;

    recBtn.onclick = async function() {
        let stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        recorder = new MediaRecorder(stream);

        recorder.ondataavailable = e => chunks.push(e.data);

        recorder.onstop = async () => {
            let blob = new Blob(chunks, { type: 'audio/webm' });
            let reader = new FileReader();

            reader.onloadend = () => {
                let base64Audio = reader.result.split(',')[1];
                const query = new URLSearchParams(window.location.search);
                query.set("audio", base64Audio);
                window.location.search = query.toString();
            };

            reader.readAsDataURL(blob);
        };

        chunks = [];
        recorder.start();
        recBtn.innerText = "‚èπ D·ª´ng ghi";

        setTimeout(() => {
            recorder.stop();
            recBtn.innerText = "üé§ B·∫•m ƒë·ªÉ h·ªèi";
        }, 3500); // Ghi 3.5 gi√¢y
    };
    </script>
    """, unsafe_allow_html=True)

    # N·∫øu c√≥ d·ªØ li·ªáu ghi √¢m
    if audio_data not in [None, ""]:
        audio_bytes = base64.b64decode(audio_data)
        user_text = transcribe(audio_bytes)
        st.info(f"B·∫°n n√≥i: {user_text}")

        answer = find_answer(user_text)
        st.success(f"Tr·ª£ l√Ω: {answer}")

        tts = gTTS(answer, lang="vi")
        tts.save("answer.mp3")
        play_audio_file("answer.mp3")

# ====== BUTTON 3 ======
with col3:
    if st.button("‚èπ K·∫øt th√∫c"):
        farewell = "C·∫£m ∆°n b·∫°n ƒë√£ tr·∫£i nghi·ªám Tr·ª£ l√Ω A.I c·ªßa Tr∆∞ng V∆∞∆°ng Garden!"
        tts = gTTS(farewell, lang="vi")
        tts.save("farewell.mp3")
        st.success(farewell)
        play_audio_file("farewell.mp3")

st.markdown("<p style='text-align:center; color: gray;'>S·∫£n ph·∫©m CLB L·∫≠p tr√¨nh 7C</p>", unsafe_allow_html=True)
>>>>>>> aeba1507bdfb064525c86015c84b5b1b37f0205d
